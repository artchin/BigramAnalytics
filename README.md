# Bigram Analytics Pipeline

**Клиент:** Маркетинговое агентство (SEO-оптимизация контента)  
**Задача:** Анализ текстового корпуса для поиска популярных ключевых фраз  
**Данные:** 4000+ статей (~12GB)

## Бизнес-контекст

Клиенту нужно было проанализировать контент конкурентов для SEO-стратегии. Ручной анализ 4000 статей нереалистичен — требовалось автоматизированное решение.

**Требования:**
- Найти самые частые словосочетания (биграммы) в корпусе
- Считать по документам, а не по вхождениям (Document Frequency)
- Обработать данные за разумное время (<10 минут)

## Архитектура

```
┌────────────┐     ┌─────────────┐     ┌─────────────┐
│   Данные   │────▶│   Job 1:    │────▶│   Job 2:    │────▶ Top-N
│   (HDFS)   │     │  Извлечение │     │ Сортировка  │      отчёт
└────────────┘     │  + подсчёт  │     │  + Top-N    │
                   └─────────────┘     └─────────────┘
                    8 reducers          1 reducer
                   (параллелизм)      (глобальный sort)
```

**Job 1:** Очистка текста → извлечение биграмм → подсчёт уникальных документов  
**Job 2:** Сортировка по частоте → выбор Top-N

## Почему Document Frequency?

Для SEO важнее знать, **в скольких документах** встречается фраза, а не сколько раз.

| Метрика | Что показывает |
|---------|----------------|
| Term Frequency | "machine learning" — 100 раз в одной статье |
| Document Frequency | "machine learning" — в 3000 из 4000 статей ✓ |

Второй вариант показывает реальный тренд.

## Результаты

```
of the      3847
in the      3652
to the      2891
on the      2234
and the     2156
...
```

**Оптимизация:** подбор числа reducers сократил время обработки с ~10 до ~5 минут.

## Запуск

```bash
./run.sh
```

## Структура проекта

```
BigramAnalytics/
├── mapper.py      # Job 1: извлечение биграмм
├── reducer.py     # Job 1: подсчёт документов
├── mapper2.py     # Job 2: инверсия для сортировки
├── reducer2.py    # Job 2: выбор Top-N
├── run.sh         # Запуск pipeline
└── README.md
```

## Стек

| Технология | Назначение |
|------------|------------|
| Hadoop HDFS | Хранение данных |
| Hadoop YARN | Управление ресурсами |
| Hadoop MapReduce | Распределённые вычисления |
| Python Streaming | Реализация mapper/reducer |

## Что отдано клиенту

- Код pipeline с документацией
- CSV с результатами анализа (Top-100 биграмм)
- Инструкция по повторному запуску
